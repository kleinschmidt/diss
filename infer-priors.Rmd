---
Title: What do you expect from an unfamiliar talker?
Author: Dave Kleinschmidt
---

```{r preamble}

library(magrittr)
library(dplyr)
library(tidyr)
library(purrr)
library(lme4)
library(ggplot2)

## devtools::install_github('kleinschmidt/phonetic-sup-unsup')
library(supunsup)

knitr::opts_chunk$set(warning = FALSE,
                      message = FALSE,
                      error = FALSE)

```

# Introduction

```{r typical-talker}

prior_lhood <- 
  supunsup::prior_stats %>%
  filter(source == 'kronrod2012') %>%
  supunsup::stats_to_lhood()

prior_class <- prior_lhood %>% lhood_to_classification()

```

# Experiment 1

# Experiment 2

```{r separatemeans-data}

sepmeans <- supunsup::separatemeans_clean

sepmeans_conds <-
  sepmeans %>%
  group_by(bvotCond, pvotCond) %>%
  summarise() %>%
  ungroup() %>%
  arrange(bvotCond, pvotCond) %>%
  mutate(vot_cond = paste(bvotCond, pvotCond),
         vot_cond = factor(vot_cond, levels=vot_cond))

sepmeans_stats <-
  sepmeans %>%
  filter(!is_test) %>%
  left_join(sepmeans_conds) %>%
  group_by(bvotCond, pvotCond, vot_cond, trueCat) %>%
  summarise(mean = mean(vot), sd = sd(vot)) %>%
  rename(category = trueCat)

sepmeans_exposure_lhood <-
  sepmeans_stats %>%
  group_by(bvotCond, pvotCond, vot_cond) %>%
  do({stats_to_lhood(.)})

sepmeans_exposure_class <-
  sepmeans_exposure_lhood %>%
  do({lhood_to_classification(.)})

```

```{r fig.width=10, fig.height=2}

sepmeans %>%
  filter(is_test) %>%
  left_join(sepmeans_conds) %>%
  ggplot(aes(x=vot, y=respP)) +
  stat_smooth(method='glm', method.args=list(family='binomial'), geom='line',
              aes(group=subject, color=vot_cond), alpha=0.2) +
  stat_smooth(method='glm', method.args=list(family='binomial'), geom='line',
              aes(color=vot_cond), size=2) +
  geom_line(data = prior_class %>% filter(vot <= 50, vot >= -10),
            linetype=2, color='black', aes(x=vot, y=prob_p)) + 
  geom_line(data = sepmeans_exposure_class %>% filter(vot <= 50, vot >= -10),
            linetype=2, size=2, aes(x=vot, y=prob_p, color=vot_cond)) + 
  facet_grid(.~vot_cond)


```

```{r }

sepmeans %>%
  filter(is_test) %>%
  left_join(sepmeans_conds) %>%
  ggplot(aes(x=vot, y=respP)) +
  stat_smooth(method='glm', method.args=list(family='binomial'), geom='line',
              aes(color=vot_cond), size=2) +
  geom_line(data = prior_class %>% filter(vot <= 50, vot >= -10),
            linetype=2, color='black', aes(x=vot, y=prob_p)) + 
  geom_line(data = sepmeans_exposure_class %>% filter(vot <= 50, vot >= -10),
            linetype=2, size=2, aes(x=vot, y=prob_p, color=vot_cond))

```

## Mixed-effects model

```{r sepmeans-prepare-lmer}

sepmeans_conds <-
  sepmeans %>%
  group_by(bvotCond, pvotCond) %>%
  summarise() %>%
  ungroup() %>%
  arrange(bvotCond, pvotCond) %>%
  mutate(vot_cond = paste(bvotCond, pvotCond),
         vot_cond = factor(vot_cond, levels=vot_cond))

cs <- contr.helmert(sepmeans_conds$vot_cond) %*% diag(1/(1:4))
colnames(cs) <- levels(sepmeans_conds$vot_cond)[2:5]
contrasts(sepmeans_conds$vot_cond) <- cs
  

# process data for modeling:
sepmeans_test <- sepmeans %>%
  # only modeling test trials:
  filter(is_test) %>%
  # convert b/p means into center + distance
  mutate(vot_cond_center = bvotCond + pvotCond,
         vot_cond_dist = pvotCond - bvotCond) %>%
  left_join(sepmeans_conds, by=c('bvotCond', 'pvotCond')) %>%
  # center/10 and scaled versions of continuous predictors
  mutate_each(funs(c10 = (. - mean(.))/10,
                   scale = (. - mean(.))/sd(.)),
              vot, vot_cond_center, vot_cond_dist, trial)

summary(sepmeans_test)

```

Lots of convergence issues with LMER.

```{r sepmeans-run-lmer, cache=TRUE}



m0 <- glmer(respP ~ 1 + vot_c10 + vot_cond + trial_c10 +
              (1 | subject),
            data = sepmeans_test, family='binomial')

summary(m0)

m0.1 <- glmer(respP ~ 1 + vot_c10 + vot_cond + trial_c10 +
                (1 + vot_c10 | subject),
              data = sepmeans_test, family='binomial')

summary(m0.1)

m0.2 <- glmer(respP ~ 1 + vot_c10 + vot_cond + trial_c10 +
                (1 + vot_c10 || subject),
              data = sepmeans_test, family='binomial')

summary(m0.2)

## m1 <- glmer(respP ~ 1 + vot_c10 * vot_cond * trial_c10 +
##               (1 + vot_c10 * trial_c10 | subject),
##             data = sepmeans_test, family='binomial')

## summary(m1)

```

```{r sepmeans-lmer-table, results='asis'}
stargazer::stargazer(m0, m0.1, m0.2, star.cutoffs=c(0.05, 0.01, 0.001), type='html')
```

## Category boundary analysis

```{r fit-cat-bounds}

boundaries <- sepmeans %>%
  filter(is_test) %>%
  group_by(bvotCond, pvotCond, subject) %>%
  mutate(trial = trial - min(trial)) %>% 
  do({ glm(respP ~ vot * trial, family='binomial', data=.) %>%
         broom::tidy() %>%
         select(term, estimate)
  }) %>%
  ungroup() %>%
  spread(term, estimate) %>%
  mutate(boundary = -`(Intercept)` / vot) %>%
  left_join(sepmeans_conds)

```

```{r}

ggplot(boundaries, aes(x=vot_cond, y=boundary)) +
  geom_violin() +
  stat_summary(fun.data=mean_cl_boot, geom='pointrange') +
  lims(y = c(-20, 60))

```

## Discussion

The effect of this manipulation is pretty small. In fact, it appears that moving the /b/ mean VOT from -20 to -50 and even -80 has little additional effect on the category boundary, even though each of these changes would move the boundary by -15ms VOT each (if the prior was completely ignored).

At first glance, this is surprising. But when you consider the _structure_ of how mean VOT varies across categories, it begins to make some sense. @Chodroff2015, for instance, found that across talkers, the VOTs of different places of articulation and voicing categories were strongly positively correlated. If listeners are sensitive to this correlation structure, the resulting prior on their adaptation would effectively filter out portions of the variability that are not positively correlated across categories.

Another possibility is that listeners are sensitive to the possibility of talkers producing a distinct cluster of pre-voiced /b/s that have large negative VOTs. When the /b/ mean enters this very-low-VOT range, it no longer affects the category boundary any more, since that is primarily determined by the short-lag category that most talkers who prevoice still produce occasionally.
